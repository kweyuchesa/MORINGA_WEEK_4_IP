{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import seaborn as sns \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://bit.ly/Autolibdataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset url\n",
    "url = 'http://bit.ly/Autolibdataset'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SQL ENVIRONMENT TO LOAD HUGE DATASET\n",
    "import os\n",
    "import csv\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "csv_database = create_engine('sqlite:////csv_database.db')\n",
    "chunk_size = 1000000\n",
    "i = 0\n",
    "j = 0\n",
    "for df in pd.read_csv(url, chunksize = chunk_size, iterator = True):\n",
    "    df = df.rename(columns = {c: c.replace(' ','') for c in df.columns})\n",
    "    df.index += j\n",
    "\n",
    "df.to_sql('auto', csv_database, if_exists = 'append' )\n",
    "j = df.index[-1]+1\n",
    "\n",
    "print(' | index: {}'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retreaving csv file into our sql lite environment \n",
    "auto = pd.read_sql_query('SELECT * \n",
    "                         from auto \n",
    "                         WHERE city == \"Paris\" ', csv_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming our dataset\n",
    "df = auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview of our dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for Validity and Dropping Unnecesary columns/Variables \n",
    "df.drop(['Unnamed', 'Displayed Comment', 'ID', 'Geo Point', 'Scheduled at ''Address', 'Cars'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy - Checking for Outliers\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_no_outliers = df < (Q1 - 1.5 * IQR)| df > (Q3 + 1.5 * IQR)\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accertain our outliers are out - checking the columns types \n",
    "df_no_outliers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETENESS - CHECKING FOR MISSING VALUES \n",
    "df_no_outliers = dff\n",
    "\n",
    "dff.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicates and Drop them ~ Scheduled at has the most duplicates 14310213  \n",
    "dff.[dff.duplicated(subset = None, Keep = 'first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort values by ID\n",
    "dff.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNIFORMITY ~ DATE TYPE CONVERSION \n",
    "from datetime import date\n",
    "\n",
    "dff['Date'] = dff.apply(lambda row: datetime(row['year'], row['month'], row['day'], row['hour'], \n",
    "                                             row['minute'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING OUR CLEAN DATASET\n",
    "dff.head()\n",
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING THE CLEAN DATASET AS CSV\n",
    "dff = pd.to_csv('autolib.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANSWERING THE RESEARCH QUESTIONS \n",
    "#1. What was the most popular hour of the day for picking up a shared electric car (Bluecar) \n",
    "#in the city of Paris over the month of April 2018?\n",
    "\n",
    "dff[dff['city'] == 'Paris'] #ensuring the city is Paris \n",
    "\n",
    "dff = dff[dff['bluecar_counter']==dff['bluecar_counter'].min()] #this lists the hours for picking the cars \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What is the most popular postal code per hour for returning blue cars? 78005 most popular with 14419 units of cars \n",
    "\n",
    "dff.groupby('postal_code',dff.date.dt.hour,['bluecar_counter'].count().sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Most Popular Station - for picking blue cars  \n",
    "\n",
    "dff.groupby('public_name','cars'].sum().sort_values(ascending = False).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Most Popular Station at the most popular picking hour for blue cars \n",
    "\n",
    "dff.groupby('public_name',dff.date.dt.hour.['bluecar_counter'],['bluecar_counter'].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Most Popular Station at the most popular picking hour for Utilib_counter \n",
    "\n",
    "dff.groupby('public_name',dff.date.dt.hour.['utilib_counter'],['utilib_counter'].count().sort_values(ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
