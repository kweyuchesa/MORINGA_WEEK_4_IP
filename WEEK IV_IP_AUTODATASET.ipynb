{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import seaborn as sns \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://bit.ly/Autolibdataset'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset url\n",
    "url = 'http://bit.ly/Autolibdataset'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SQL ENVIRONMENT TO LOAD HUGE DATASET\n",
    "import os\n",
    "import csv\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "csv_database = create_engine('sqlite:////csv_database.db')\n",
    "chunk_size = 1000000\n",
    "i = 0\n",
    "j = 0\n",
    "for df in pd.read_csv(url, chunksize = chunk_size, iterator = True):\n",
    "    df = df.rename(columns = {c: c.replace(' ','') for c in df.columns})\n",
    "    df.index += j\n",
    "\n",
    "df.to_sql('auto', csv_database, if_exists = 'append' )\n",
    "j = df.index[-1]+1\n",
    "\n",
    "print(' | index: {}'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retreaving csv file into our sql lite environment \n",
    "auto = pd.read_sql_query('SELECT * \n",
    "                         from auto \n",
    "                         WHERE city == \"Paris\" ', csv_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the size of the dataset \n",
    "auto.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview of our dataset\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retreaving csv file into our sql lite environment \n",
    "auto = pd.read_sql_query('SELECT * from auto WHERE city == \"Paris\" ', csv_database, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMATTING THE Date_time column\n",
    "auto = pd.read_csv('auto_clean.csv', dtype = {'year':str,'month':str,'day':str,'hour':str,'minute':str })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['date'] = auto.year.str.cat([auto.month,auto.day], sep = '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['time'] = auto.hour.str.cat([auto.minute], sep = ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['date_time'] = auto.date.str.cat([auto.time], sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns \n",
    "auto.drop(['year','month', 'day', 'minute',  'date', 'time'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreating a new csv dataset\n",
    "auto.to_csv('auto_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecesarry columns \n",
    "auto.drop(['Unnamed: 0', 'Unnamed:0', 'index',  'Displayedcomment', 'ID', 'Geopoint', \n",
    "           'Scheduledat','Address','ChargeSlots', 'ChargingStatus','Kind', 'Rentalstatus','Slots',],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETENESS - CHECKING FOR MISSING VALUES \n",
    "auto.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicates and Drop them ~ Scheduled at has the most duplicates 14310213  \n",
    "auto[auto.duplicated(subset = None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort values by ID\n",
    "dff.sort_values('Publicname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if its only city we are dealing with \n",
    "auto.City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING OUR CLEAN DATASET\n",
    "auto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING THE CLEAN DATASET AS CSV\n",
    "auto = pd.to_csv('autolib.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANSWERING THE RESEARCH QUESTIONS \n",
    "#1. What was the most popular hour of the day for picking up a shared electric car (Bluecar) \n",
    "#in the city of Paris over the month of April 2018?\n",
    "\n",
    "auto[auto.City == 'Paris']  #ensuring the city is Paris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this lists the hours for picking the cars \n",
    "auto.groupby([auto.date_time.dt.hour])['Bluecarcounter'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What is the most popular postal code per hour for returning blue cars? 78005 most popular with 14419 units of cars \n",
    "\n",
    "auto.groupby(['Postalcode',auto.date_time.dt.hour,'Bluecarcounter'])['Bluecarcounter'].count().sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Most Popular Station - for picking blue cars  \n",
    "\n",
    "auto.groupby(['Publicname','Bluecarcounter'])['Publicname'].count().sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Most Popular Station at the most popular picking hour for blue cars \n",
    "\n",
    "auto.groupby(['Publicname',auto.date_time.dt.hour,'Utilibcounter'])['Utilibcounter'].count().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Most Popular Station at the most popular picking hour for Utilib_counter \n",
    "\n",
    "dff.groupby('public_name',dff.date.dt.hour.['utilib_counter'],['utilib_counter'].count().sort_values(ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
