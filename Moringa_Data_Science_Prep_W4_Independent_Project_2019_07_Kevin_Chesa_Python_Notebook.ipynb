{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moringa_Data_Science_Prep_W4_Independent_Project_2019_07_Kevin_Chesa_Python_Notebook",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kweyuchesa/WEEK-4---MORINGA-IP/blob/master/Moringa_Data_Science_Prep_W4_Independent_Project_2019_07_Kevin_Chesa_Python_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en8bwbkBgj4O",
        "colab_type": "text"
      },
      "source": [
        "#libraries for our analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auRqzVGTgis_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import the packages and libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly as py\n",
        "import seaborn as sns \n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPq8GSURg4d2",
        "colab_type": "text"
      },
      "source": [
        "Importing Our **Autolib_dataset.xlsx** Dataset for analysis and Exploration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MgxXOv8hBzk",
        "colab_type": "code",
        "outputId": "426c8732-2aea-4aac-9e1d-e3457cd407c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Let's read the data from the CSV file and create the dataframe to be used\n",
        "url = 'http://bit.ly/Autolibdataset'\n",
        "url"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://bit.ly/Autolibdataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTDAiWOw2fQ",
        "colab_type": "text"
      },
      "source": [
        "#Creating an SQL Environment for Loading Huge Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy72tOR2DLsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "csv_database = create_engine('sqlite:////csv_database.db')\n",
        "chunk_size = 1000000\n",
        "i = 0\n",
        "j = 0\n",
        "for df in pd.read_csv(url, chunksize = chunk_size, iterator = True):\n",
        "    df = df.rename(columns = {c: c.replace(' ','') for c in df.columns})\n",
        "    df.index += j\n",
        "\n",
        "df.to_sql('auto', csv_database, if_exists = 'append' )\n",
        "j = df.index[-1]+1\n",
        "\n",
        "print(' | index: {}'.format(j))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4QRKEWGDXSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding the size of the dataset \n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPZWNAVVw-YM",
        "colab_type": "text"
      },
      "source": [
        "#Retreaving csv file into our sql lite environment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cad_Oz_j_OV3",
        "colab_type": "text"
      },
      "source": [
        "DESCRIBING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iM9O5jb_VXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retreaving csv file into our sql lite environment \n",
        "auto = pd.read_sql_query('SELECT * from auto WHERE city == \"Paris\" ', csv_database)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzP0Og__W-a",
        "colab_type": "text"
      },
      "source": [
        "Renaming Our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bjslbPN_bni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = auto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AYOO3Fn_crR",
        "colab_type": "text"
      },
      "source": [
        "Preview our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu6om68r_fui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxzrmJOS_hV6",
        "colab_type": "text"
      },
      "source": [
        "#Validity ~ Dropping Unnecesary columns/Variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-M0H-n9_l2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['Unnamed', 'Displayed Comment', 'ID', 'Geo Point', 'Scheduled at ''Address', 'Cars'],axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCLC8eMd_peR",
        "colab_type": "text"
      },
      "source": [
        "#Accuracy ~ Dealing with Outliers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3YH8A9N_rzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy - Checking for Outliers\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "df_no_outliers = df < (Q1 - 1.5 * IQR)| df > (Q3 + 1.5 * IQR)\n",
        "df_no_outliersday1 = pd.read_csv('MoringaSchool_CB_CDR_20120507.csv')\n",
        "day1.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwCXln_Z_u8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accertain our outliers are out - checking the columns types \n",
        "df_no_outliers.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojw5FHpC_xE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPORTING THE 3 DAYS DATASETS \n",
        "day3 = pd.read_csv('MoringaSchool_CB_CDR_20120509.csv')\n",
        "day3.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMr2RcbB_y4Z",
        "colab_type": "text"
      },
      "source": [
        "#Completeness ~ Null Values Assessment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OMsED9p_1ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_no_outliers = dff\n",
        "\n",
        "dff.isnull().sum().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6yvLCiG_2ZR",
        "colab_type": "text"
      },
      "source": [
        "#Duplicates "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjbSxQrp_5_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Duplicates and Drop them ~ Scheduled at has the most duplicates 14310213  \n",
        "dff.[dff.duplicated(subset = None, Keep = 'first')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL2fKCJi_7BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sort values by ID\n",
        "dff.sort_values()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihLZpeg__c6",
        "colab_type": "text"
      },
      "source": [
        "#Uniformity ~ Date Type Conversion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCioXDSWACww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combining the datasets for uniform analysis\n",
        "df=pd.concat([day1, day2, day3], ignore_index=True)\n",
        "df.head()#UNIFORMITY ~ DATE TYPE CONVERSION \n",
        "from datetime import date\n",
        "\n",
        "dff['Date'] = dff.apply(lambda row: datetime(row['year'], row['month'], row['day'], row['hour'], \n",
        "                                             row['minute'], axis = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j00F5yt8AFNg",
        "colab_type": "text"
      },
      "source": [
        "Displaying Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MffuERhNAL34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DISPLAYING OUR CLEAN DATASET\n",
        "dff.head()\n",
        "dff.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxn2SsUyAOYI",
        "colab_type": "text"
      },
      "source": [
        "Saving our clean dataset as csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnbpTq9nASCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SAVING THE CLEAN DATASET AS CSV\n",
        "dff = pd.to_csv('autolib.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL9GKR4aATwg",
        "colab_type": "text"
      },
      "source": [
        "#ANALYSIS ~ Answering Research Questions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6BUYk_5AcHw",
        "colab_type": "text"
      },
      "source": [
        "1. What was the most popular hour of the day for picking up a shared electric car (Bluecar) \n",
        "in the city of Paris over the month of April 2018?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcDmGQOwAeFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dff[dff['city'] == 'Paris'] #ensuring the city is Paris \n",
        "\n",
        "dff = dff[dff['bluecar_counter']==dff['bluecar_counter'].min()] #this lists the hours for picking the cars "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LX0-UfIAf1g",
        "colab_type": "text"
      },
      "source": [
        "2.What is the most popular postal code per hour for returning blue cars? 78005 most popular with 14419 units of cars "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN6D02dcAhho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dff.groupby('postal_code',dff.date.dt.hour,['bluecar_counter'].count().sort_values(ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K5HDeBoAjI5",
        "colab_type": "text"
      },
      "source": [
        "3. Most Popular Station - for picking blue cars  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RkqVomCAluQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dff.groupby('public_name','cars'.sum().sort_values(ascending = False).head(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WYU4i00AoXR",
        "colab_type": "text"
      },
      "source": [
        "4. Utilib_counter Station at the most popular picking hour for blue cars "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8znYlX2KAqJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dff.groupby('public_name',dff.date.dt.hour.['utilib_counter'],['utilib_counter'].count().sort_values(ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GvPRi4cAx4j",
        "colab_type": "text"
      },
      "source": [
        "5. "
      ]
    }
  ]
}